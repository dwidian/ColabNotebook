{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleGAN2 Faces Combination.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNKg3erBcpf6VRo9JLXPeJE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dwidian/ColabNotebook/blob/master/StyleGAN2_Faces_Combination.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DHZ-PbC68V0",
        "colab_type": "text"
      },
      "source": [
        "**Warning!** Please enable GPU from \"Runtime\", \"Change runtime type\", set \"Hardware Accelerator\" to GPU "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4z8rLt0c-3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --force tqdm==4.24.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEnEHEYF3obQ",
        "colab_type": "text"
      },
      "source": [
        "Clone styllegan2encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tCZj5m1dLqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/robertluxemburg/stylegan2encoder\n",
        "%cd stylegan2encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CVgVtRIdSdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir aligned_images raw_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-A1Vo2K4Y3Y",
        "colab_type": "text"
      },
      "source": [
        "Put your images into /raw_images/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08feFWmD42X7",
        "colab_type": "text"
      },
      "source": [
        "Let's view our images :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q85__Ti-dfLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import PIL.Image\n",
        "img1 = PIL.Image.open('raw_images/Najwa.jpg')\n",
        "wpercent = (256/float(img1.size[0]))\n",
        "hsize = int((float(img1.size[1])*float(wpercent)))\n",
        "img1 = img1.resize((256,hsize), PIL.Image.LANCZOS)\n",
        "img2 = PIL.Image.open('raw_images/Raisa.jpg')\n",
        "wpercent = (256/float(img2.size[0]))\n",
        "hsize = int((float(img2.size[1])*float(wpercent)))\n",
        "img2 = img2.resize((256,hsize), PIL.Image.LANCZOS)\n",
        "display(img1,img2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8g6nSUM5Eas",
        "colab_type": "text"
      },
      "source": [
        "Now we need to get just the faces, cropped and aligned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVXWfwa1eETY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python align_images.py raw_images/ aligned_images/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upo8LwvieM-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display(PIL.Image.open('aligned_images/Najwa_01.png').resize((256,256)))\n",
        "display(PIL.Image.open('aligned_images/Raisa_01.png').resize((256,256)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqvOhrvzf_bA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6Ubsh0z5bXT",
        "colab_type": "text"
      },
      "source": [
        "Finally, let's try encoding some images into a latent representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o19BkHLneneq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python encode_images.py aligned_images/ generated_images/ latent_representations/ \\\n",
        "    --vgg_url=https://rolux.org/media/stylegan/vgg16_zhang_perceptual.pkl \\\n",
        "    --lr=0.25 --iterations=1000 --use_l1_penalty=0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdDaiObEffYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display(PIL.Image.open('generated_images/Najwa_01.png').resize((512, 512)))\n",
        "display(PIL.Image.open('generated_images/Raisa_01.png').resize((512, 512)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKw4YZYjnv1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import pickle\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "# load the StyleGAN model into Colab\n",
        "URL_FFHQ = 'https://drive.google.com/uc?id=1spmHuEW7ie62nXT0qIwFDP7EdAyD112-'\n",
        "tflib.init_tf()\n",
        "with dnnlib.util.open_url(URL_FFHQ) as f:\n",
        "    generator_network, discriminator_network, Gs_network = pickle.load(f)\n",
        "# load the latents\n",
        "s1 = np.load('latent_representations/Raisa_01.npy')\n",
        "s2 = np.load('latent_representations/Najwa_01.npy')\n",
        "s1 = np.expand_dims(s1,axis=0)\n",
        "s2 = np.expand_dims(s2,axis=0)\n",
        "# combine the latents somehow... let's try an average:\n",
        "savg = 0.5*(s1+s2)\n",
        "# run the generator network to render the latents:\n",
        "synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\n",
        "images = Gs_network.components.synthesis.run(savg, randomize_noise=False, **synthesis_kwargs)\n",
        "display(PIL.Image.fromarray(images.transpose((0,2,3,1))[0], 'RGB').resize((512,512),PIL.Image.LANCZOS))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}